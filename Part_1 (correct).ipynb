{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c17f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "#import plotly.io as pio\n",
    "#pio.renderers.default = 'notebook'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0801a3e-d7ed-4fb0-a35c-b46178d6c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"average-latitude-longitude-countries.csv\"\n",
    "dfA = pd.read_csv(file_path)\n",
    "\n",
    "def categorize_latitude(latitude):\n",
    "    if latitude > 23.5:\n",
    "        return \"North of Tropic of Cancer\"\n",
    "    elif 0 < latitude <= 23.5:\n",
    "        return \"Tropic of Cancer\"\n",
    "    elif latitude == 0:\n",
    "        return \"Equator\"\n",
    "    elif -23.5 <= latitude < 0:\n",
    "        return \"Tropic of Capricorn\"\n",
    "    else:\n",
    "        return \"South of Tropic of Capricorn\"\n",
    "\n",
    "dfA['Category'] = dfA['Latitude'].apply(categorize_latitude)\n",
    "\n",
    "grouped = dfA.groupby('Category')['Country'].apply(list)\n",
    "\n",
    "#for category, countries in grouped.items():\n",
    "    #print(f\"Category: {category}\")\n",
    "    #print(f\"Number of countries: {len(countries)}\")\n",
    "    #print(\"Countries:\", \", \".join(countries))\n",
    "    #print(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "120bf63c-44fa-4d79-b9a5-3670d1720e26",
   "metadata": {},
   "source": [
    "file_names = [\n",
    "    'processed_Coal and coke.csv',\n",
    "    'processed_Natural gas.csv',\n",
    "    'processed_Petroleum and other liquids.csv',\n",
    "    \"processed_Biofuels.csv\",\n",
    "    \"processed_Electricity.csv\",\n",
    "    \"processed_Hydrocarbon gas liquids.csv\",\n",
    "    \"modified2_primary_energy.csv\",\n",
    "    \"processed_emissions_modified.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    df['Country'] = df['Country'].str.replace(' ', '')\n",
    "    df_merged = pd.merge(df, dfA, on='Country', how='left')\n",
    "    \n",
    "    output_file_name = f'merged_{file_name}'\n",
    "    df_merged.to_csv(output_file_name, index=False)\n",
    "    \n",
    "    print(f\"Processed and saved: {output_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bfb59-ddb6-4064-bc67-0990cb0384a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = pd.read_csv('merged_processed_emissions_modified.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351359b8-be14-4311-9d47-aa6f202bdc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_space_between_case_changes(text):\n",
    "    return re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', text)\n",
    "emissions['Country'] = emissions['Country'].apply(add_space_between_case_changes)\n",
    "\n",
    "updates = {\n",
    "    'United States': {'Latitude': 38.7946, 'Longitude': -106.5348},\n",
    "    'Russia': {'Latitude': 61.5240, 'Longitude': 105.3188}\n",
    "}\n",
    "for country, coords in updates.items():\n",
    "    emissions.loc[emissions['Country'] == country, ['Latitude', 'Longitude']] = [coords['Latitude'], coords['Longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a171e22-977c-47f5-b135-64c54ba6d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdpC = pd.read_excel('GDP by capita2.xls')\n",
    "gdp = pd.read_excel('GDP2.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a374671-0f27-4591-86fc-6fdf75cfc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdp_renamed = gdp.rename(columns=lambda col: f'{str(col)}_gdp' if str(col).isdigit() else col)\n",
    "gdp_renamed['Country Name'] = gdp_renamed['Country Name'].replace('Russian Federation', 'Russia')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f45f3-10b0-4928-b7ae-8ab7101c0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = gdp_renamed['Country Name'].unique()\n",
    "print(\"Unique countries in the 'Country' column:\")\n",
    "#for country in unique_countries:\n",
    "    #print(country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e071a7b-38dc-4962-8959-b92b386336ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = emissions['Country'].unique()\n",
    "print(\"Unique countries in the 'Country' column:\")\n",
    "#for country in unique_countries:\n",
    "    #print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9252b-f4fb-445e-aaaf-4667bb3f7d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_dict = {\n",
    "    \"European Union\": (50.8503, 4.3517),  # Brussels, EU headquarters\n",
    "    \"Czechia\": (49.8175, 15.4730),\n",
    "    \"British Virgin Islands\": (18.4207, -64.6399),\n",
    "    \"Burkina Faso\": (12.2383, -1.5616),\n",
    "    \"Cabo Verde\": (16.5388, -23.0418),\n",
    "    \"Cayman Islands\": (19.3133, -81.2546),\n",
    "    \"Central African Republic\": (6.6111, 20.9394),\n",
    "    \"Dominican Republic\": (18.7357, -70.1627),\n",
    "    \"El Salvador\": (13.7942, -88.8965),\n",
    "    \"Equatorial Guinea\": (1.6508, 10.2679),\n",
    "    \"Eswatini\": (-26.5225, 31.4659),\n",
    "    \"Faroe Islands\": (61.8926, -6.9118),\n",
    "    \"French Polynesia\": (-17.6797, -149.4068),\n",
    "    \"Kosovo\": (42.6026, 20.9020),\n",
    "    \"Libya\": (26.3351, 17.2283),\n",
    "    \"Moldova\": (47.4116, 28.3699),\n",
    "    \"New Caledonia\": (-20.9043, 165.6180),\n",
    "    \"North Macedonia\": (41.6086, 21.7453),\n",
    "    \"Northern Mariana Islands\": (15.0979, 145.6739),\n",
    "    \"Papua New Guinea\": (-6.314993, 143.95555),\n",
    "    \"Saudi Arabia\": (23.8859, 45.0792),\n",
    "    \"Sierra Leone\": (8.4606, -11.7799),\n",
    "    \"Solomon Islands\": (-9.6457, 160.1562),\n",
    "    \"South Africa\": (-30.5595, 22.9375),\n",
    "    \"South Sudan\": (6.8770, 31.3070),\n",
    "    \"Sri Lanka\": (7.8731, 80.7718),\n",
    "    \"Tanzania\": (-6.3690, 34.8888),\n",
    "    \"Timor-Leste\": (-8.8742, 125.7275),\n",
    "    \"United Arab Emirates\": (23.4241, 53.8478),\n",
    "    \"American Samoa\": (-14.2710, -170.1322),\n",
    "    \"Costa Rica\": (9.7489, -83.7534),\n",
    "    \"New Zealand\": (-40.9006, 174.8860),\n",
    "    \"Puerto Rico\": (18.2208, -66.5901),\n",
    "    \"Turkiye\": (38.9637, 35.2433),\n",
    "    \"United Kingdom\": (55.3781, -3.4360)\n",
    "}\n",
    "\n",
    "def update_lat_long(row):\n",
    "    country = row['Country']\n",
    "    if country in lat_long_dict:\n",
    "        row['Latitude'], row['Longitude'] = lat_long_dict[country]\n",
    "    return row\n",
    "\n",
    "emissions = emissions.apply(update_lat_long, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185cdf0c-063c-47be-8ca8-e3c9a6fd57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(emissions, gdp_renamed, left_on='Country', right_on='Country Name')\n",
    "\n",
    "years = [str(year) for year in range(2000, 2022)]\n",
    "\n",
    "for year in years:\n",
    "    emissions_col = year   \n",
    "    gdp_col = f'{year}_gdp'  \n",
    "    \n",
    "    if emissions_col in merged_df.columns and gdp_col in merged_df.columns:\n",
    "        merged_df[emissions_col] = pd.to_numeric(merged_df[emissions_col], errors='coerce')\n",
    "        merged_df[gdp_col] = pd.to_numeric(merged_df[gdp_col], errors='coerce')\n",
    "\n",
    "        ratio_col = f'ratio_{year}'  \n",
    "        merged_df[ratio_col] = merged_df[gdp_col] / merged_df[emissions_col]\n",
    "\n",
    "valid_ratio_columns = [f'ratio_{year}' for year in years]\n",
    "\n",
    "columns_to_include = ['Country', 'Type of Emission'] + valid_ratio_columns\n",
    "if 'Latitude' in merged_df.columns:\n",
    "    columns_to_include.append('Latitude')\n",
    "if 'Longitude' in merged_df.columns:\n",
    "    columns_to_include.append('Longitude')\n",
    "\n",
    "filtered_df = merged_df.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "new_dataset_with_ratios = filtered_df[columns_to_include].dropna(how='all', subset=valid_ratio_columns)\n",
    "\n",
    "#new_dataset_with_ratios.to_csv('new_dataset_with_ratios.csv', index=False)\n",
    "\n",
    "new_dataset_with_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ebab5-5042-4dd9-add0-b3a1d6ad23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEEMS COOL BUT NEED MORE WORK ON IT \n",
    "\n",
    "correlation = new_dataset_with_ratios[['ratio_2019', 'Latitude', 'Longitude']].corr()\n",
    "\n",
    "# Create heatmap of correlations\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title('Correlation of Ratios with Latitude and Longitude (2022)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee7cdc-6a59-4143-a2d0-3969190f789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_countries = px.data.gapminder()['country'].unique()\n",
    "\n",
    "print(\"Supported countries for px.choropleth:\")\n",
    "#for country in sorted(supported_countries):\n",
    "    #print(country)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7df8189e-b193-43a9-a2be-8fce3898e0bf",
   "metadata": {},
   "source": [
    "melted_df['Year'] = melted_df['Year'].astype(str)\n",
    "\n",
    "# Extract year from 'Year' column\n",
    "melted_df['Year'] = melted_df['Year'].str.extract(r'(\\d{4})')\n",
    "\n",
    "# Drop rows where 'Year' is NaN (if any)\n",
    "melted_df = melted_df.dropna(subset=['Year'])\n",
    "\n",
    "# Convert 'Year' to integer\n",
    "melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "\n",
    "# Get the unique countries from melted_df\n",
    "countries_in_dataset = melted_df['Country'].unique()\n",
    "\n",
    "# Fetch a sample plotly dataset with supported countries\n",
    "supported_countries = px.data.gapminder()['country'].unique()\n",
    "\n",
    "# Find countries not shown on the map\n",
    "countries_not_supported = [country for country in countries_in_dataset if country not in supported_countries]\n",
    "\n",
    "# Print the countries not supported\n",
    "print(\"Countries not supported or not shown on the map:\")\n",
    "#for country in countries_not_supported:\n",
    "    #print(country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b81cbd-4696-43aa-8df8-7171f502e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = [\n",
    "    'Cyprus', 'Estonia', 'Latvia', 'Lithuania', 'Luxembourg', 'Malta', \n",
    "    'Armenia', 'Aruba', 'Azerbaijan', 'Barbados', 'Belarus', 'Belize', \n",
    "    'Bermuda', 'Bhutan', 'Dominica', 'Fiji', 'Georgia', 'Greenland', \n",
    "    'Grenada', 'Guyana', 'Kazakhstan', 'Kiribati', 'Maldives', 'Nauru', \n",
    "    'Qatar', 'Russia', 'Samoa', 'Seychelles', 'Suriname', 'Tajikistan', \n",
    "    'Tonga', 'Turkmenistan', 'Tuvalu', 'Ukraine', 'Uzbekistan', 'Vanuatu', 'Guam'\n",
    "]\n",
    "\n",
    "emission_countries = emissions['Country'].unique()\n",
    "countries_in_emissions = [country for country in country_list if country in emission_countries]\n",
    "#print(\"Countries from the list found in the 'emissions' dataset:\")\n",
    "#for country in countries_in_emissions:\n",
    "    #print(country)\n",
    "countries_not_in_emissions = [country for country in country_list if country not in emission_countries]\n",
    "\n",
    "#print(\"\\nCountries from the list NOT found in the 'emissions' dataset:\")\n",
    "#for country in countries_not_in_emissions:\n",
    "    #print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1ef13-dce0-4f64-b144-b822435001c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_countries = merged_df['Country Name'].unique()\n",
    "\n",
    "countries_in_merged = [country for country in country_list if country in merged_countries]\n",
    "#print(\"Countries from the list found in the 'merged_df' dataset:\")\n",
    "#for country in countries_in_merged:\n",
    "    #print(country)\n",
    "countries_not_in_merged = [country for country in country_list if country not in merged_countries]\n",
    "\n",
    "#print(\"\\nCountries from the list NOT found in the 'merged_df' dataset:\")\n",
    "#for country in countries_not_in_merged:\n",
    "    #print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a77dbc-fc6e-4a26-b0fd-2a1239e8273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_types = [\n",
    "    '        CO2 emissions (MMtonnes CO2)',\n",
    "    '            Coal and coke (MMtonnes CO2)',\n",
    "    '            Consumed natural gas (MMtonnes CO2)',\n",
    "    '            Petroleum and other liquids (MMtonnes CO2)'\n",
    "]\n",
    "\n",
    "color_ranges = {\n",
    "    '        CO2 emissions (MMtonnes CO2)': (0, 9000000000),  # Example range\n",
    "    '            Coal and coke (MMtonnes CO2)': (0, 50000000000),  # Example range\n",
    "    '            Consumed natural gas (MMtonnes CO2)': (0, 30000000000),  # Example range\n",
    "    '            Petroleum and other liquids (MMtonnes CO2)': (0, 9000000000)  # Example range\n",
    "}\n",
    "\n",
    "for emission in emission_types:\n",
    "    filtered_df = new_dataset_with_ratios[new_dataset_with_ratios['Type of Emission'] == emission]\n",
    "\n",
    "    melted_df = filtered_df.melt(id_vars=['Country', 'Type of Emission'], \n",
    "                                 var_name='Year', \n",
    "                                 value_name='Ratio')\n",
    "\n",
    "    melted_df['Year'] = melted_df['Year'].str.extract(r'(\\d{4})')\n",
    "\n",
    "    melted_df = melted_df.dropna(subset=['Year'])\n",
    "\n",
    "    melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "\n",
    "    cmin, cmax = color_ranges[emission] \n",
    "\n",
    "    fig = px.choropleth(melted_df, \n",
    "                        locations=\"Country\", \n",
    "                        locationmode='country names',  \n",
    "                        color=\"Ratio\", \n",
    "                        hover_name=\"Country\", \n",
    "                        animation_frame=\"Year\",  \n",
    "                        title=f\"Choropleth Map of {emission.strip()} (2000-2021)\",\n",
    "                        color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "    fig.update_coloraxes(cmin=cmin, cmax=cmax, colorbar_title=\"Emissions-to-GDP Ratio\")\n",
    "\n",
    "    fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\", showland=True, landcolor=\"lightgray\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1200,  \n",
    "        height=800,  \n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f50482e-bf0e-4b9a-b58e-6109c9c61fd8",
   "metadata": {},
   "source": [
    "\n",
    "# Check if these countries exist in 'emissions' dataset's 'Country' column\n",
    "emissions_exists = emissions['Country'].isin(countries_to_check)\n",
    "\n",
    "# Check if these countries exist in 'gdp_renamed' dataset's 'Country Name' column\n",
    "gdp_exists = gdp_renamed['Country Name'].isin(countries_to_check)\n",
    "\n",
    "# Print the countries that are found in each dataset\n",
    "#print(\"Countries found in 'emissions' dataset:\")\n",
    "#print(emissions['Country'][emissions_exists].unique())\n",
    "\n",
    "#print(\"\\nCountries found in 'gdp_renamed' dataset:\")\n",
    "#print(gdp_renamed['Country Name'][gdp_exists].unique())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9afd9247-a63a-47a8-b4f0-41f5e7d0e49d",
   "metadata": {},
   "source": [
    "\n",
    "dfo = pd.read_csv('processed_emissions.csv')\n",
    "\n",
    "# Use .ffill() instead of .fillna(method='ffill')\n",
    "dfo['Country'] = dfo['Country'].ffill()\n",
    "\n",
    "if dfo['Country'].notna().iloc[0] != 'European Union':\n",
    "    dfo['Country'] = dfo['Country'].apply(lambda x: 'European Union' \n",
    "                                          if x == dfo['Country'].notna().iloc[0] else x)\n",
    "\n",
    "# Use .ffill() again for forward filling\n",
    "dfo['Country'] = dfo['Country'].ffill()\n",
    "\n",
    "# Save the modified DataFrame to a CSV file\n",
    "dfo.to_csv('processed_emissions_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfE = pd.read_csv(\"merged_processed_emissions_modified.csv\")\n",
    "#print(emissions['Type of Emission'].unique())  # Show unique values in the 'Type of Emission' column\n",
    "#print(emissions['Country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc332d-cacc-47a9-b46d-3944ac0997c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_emissions = emissions['Type of Emission'].unique()\n",
    "print(unique_emissions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4300cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_df = emissions[emissions['Type of Emission'].str.strip() == 'CO2 emissions (MMtonnes CO2)']\n",
    "\n",
    "years = [str(year) for year in range(1980, 2023)]\n",
    "\n",
    "co2_df.loc[:, years] = co2_df[years].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "co2_df = co2_df.drop_duplicates(subset=['Country'])\n",
    "\n",
    "co2_df.set_index('Country', inplace=True)\n",
    "total_emissions = co2_df[years].sum(axis=1)\n",
    "\n",
    "sorted_emissions = total_emissions.sort_values(ascending=False)\n",
    "\n",
    "top_20 = sorted_emissions.head(20)\n",
    "bottom_20 = sorted_emissions.tail(20)\n",
    "\n",
    "middle_index = len(sorted_emissions) // 2\n",
    "if len(sorted_emissions) < 20:\n",
    "    middle_20 = sorted_emissions\n",
    "else:\n",
    "    middle_20 = sorted_emissions.iloc[middle_index - 5: middle_index + 5]\n",
    "\n",
    "print(\"Top 20 countries with highest CO2 emissions:\")\n",
    "print(top_20)\n",
    "print(\"\\nBottom 20 countries with lowest CO2 emissions:\")\n",
    "print(bottom_20)\n",
    "print(\"\\nMiddle 20 countries with CO2 emissions:\")\n",
    "print(middle_20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f477d1c4-8105-4594-aebc-2bcab1a10361",
   "metadata": {},
   "source": [
    "#calculte/create the stock emissions column \n",
    "\n",
    "years = [str(year) for year in range(1980, 2013)]\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "df_copy[years] = df_copy[years].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "emission_types = ['        CO2 emissions (MMtonnes CO2)',\n",
    "    '            Coal and coke (MMtonnes CO2)',\n",
    "    '            Consumed natural gas (MMtonnes CO2)',\n",
    "    '            Petroleum and other liquids (MMtonnes CO2)'\n",
    "]\n",
    "\n",
    "df_copy['Stock Emissions (1980-2012)'] = pd.NA\n",
    "\n",
    "for emission_type in emission_types:\n",
    "    mask = df_copy['Type of Emission'] == emission_type\n",
    "    df_copy.loc[mask, 'Stock Emissions (1980-2012)'] = df_copy.loc[mask, years].sum(axis=1)\n",
    "\n",
    "#remaining_mask = ~df_copy['Type of Emission'].isin(emission_types)\n",
    "#df_copy.loc[remaining_mask, 'Stock Emissions (1980-2012)'] = df_copy.loc[remaining_mask, years].sum(axis=1)\n",
    "\n",
    "df['Stock Emissions (1980-2012)'] = df_copy['Stock Emissions (1980-2012)']\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d45a1c",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL FILES WITH ONLY POSITIVES VALUES (YEAR TO YEAR)\n",
    "\n",
    "file_names = [\n",
    "    \"merged_processed_Coal and coke.csv\",\n",
    "    \"merged_processed_Natural gas.csv\",\n",
    "    \"merged_processed_Petroleum and other liquids.csv\",\n",
    "    \"merged_processed_Biofuels.csv\",\n",
    "    \"merged_processed_Electricity.csv\",\n",
    "    \"merged_modified2_primary_energy.csv\",\n",
    "    \"merged_processed_emissions_modified.csv\"\n",
    "]\n",
    "\n",
    "years_range = [str(year) for year in range(2012, 2023)]\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    for year in years_range:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "    \n",
    "    for i in range(1, len(years_range)):\n",
    "        current_year = years_range[i]\n",
    "        previous_year = years_range[i - 1]\n",
    "        percentage_change_column = f'% change {previous_year} to {current_year}'\n",
    "        \n",
    "        df.loc[:, percentage_change_column] = (\n",
    "            (df[current_year] - df[previous_year]) / df[previous_year]\n",
    "        ) * 100\n",
    "    \n",
    "    change_columns = [col for col in df.columns if col.startswith('% change')]\n",
    "    df.replace([float('inf'), -float('inf')], np.nan, inplace=True)  \n",
    "    df.dropna(subset=change_columns, inplace=True) \n",
    "    \n",
    "    all_positive = df[change_columns].gt(0).all(axis=1)\n",
    "    df = df[all_positive]\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "\n",
    "    print(f\"Filtered unique rows with all positive % change in the dataset '{file_name}':\")\n",
    "    display(df)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f3a3e-9ace-4d6f-8ca8-fb5470423f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only positive change year to year \n",
    "\n",
    "years_range = [str(year) for year in range(2012, 2023)]\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    for year in years_range:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "    for i in range(1, len(years_range)):\n",
    "        current_year = years_range[i]\n",
    "        previous_year = years_range[i - 1]\n",
    "        percentage_change_column = f'% change {previous_year} to {current_year}'\n",
    "        \n",
    "        df[percentage_change_column] = (\n",
    "            (df[current_year] - df[previous_year]) / df[previous_year]\n",
    "        ) * 100\n",
    "\n",
    "    change_columns = [col for col in df.columns if col.startswith('% change')]\n",
    "    df.replace([float('inf'), -float('inf')], np.nan, inplace=True)  \n",
    "    df.dropna(subset=change_columns, inplace=True) \n",
    "    \n",
    "    all_positive = df[change_columns].gt(0).all(axis=1)\n",
    "    df = df[all_positive]\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    melted_df = df.melt(id_vars=['Country'], \n",
    "                        value_vars=years_range, \n",
    "                        var_name='Year', \n",
    "                        value_name='Value')\n",
    "    \n",
    "    melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "    \n",
    "    fig = px.choropleth(melted_df, \n",
    "                        locations=\"Country\", \n",
    "                        locationmode='country names',  \n",
    "                        color=\"Value\", \n",
    "                        hover_name=\"Country\", \n",
    "                        animation_frame=\"Year\",  \n",
    "                        title=f\"Choropleth Map of Values Over Time ({file_name})\",\n",
    "                        color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "    fig.update_coloraxes(cmin=melted_df['Value'].min(), \n",
    "                         cmax=melted_df['Value'].max(), \n",
    "                         colorbar_title=\"Value\")\n",
    "    \n",
    "    fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\", showland=True, landcolor=\"lightgray\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1200,  \n",
    "        height=800,  \n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3416fab0-d6ea-4c1d-9668-8d356bb0b654",
   "metadata": {},
   "source": [
    "##only negative change => but not many rows that fits the requirement\n",
    "\n",
    "years_range = [str(year) for year in range(2012, 2023)]\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    for year in years_range:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "    \n",
    "    for i in range(1, len(years_range)):\n",
    "        current_year = years_range[i]\n",
    "        previous_year = years_range[i - 1]\n",
    "        percentage_change_column = f'% change {previous_year} to {current_year}'\n",
    "        \n",
    "        df[percentage_change_column] = (\n",
    "            (df[current_year] - df[previous_year]) / df[previous_year]\n",
    "        ) * 100\n",
    "\n",
    "    change_columns = [col for col in df.columns if col.startswith('% change')]\n",
    "    df.replace([float('inf'), -float('inf')], np.nan, inplace=True)  \n",
    "    df.dropna(subset=change_columns, inplace=True) \n",
    "    \n",
    "    # Select rows where all percentage changes are negative\n",
    "    all_negative = df[change_columns].lt(0).all(axis=1)\n",
    "    df = df[all_negative]\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    melted_df = df.melt(id_vars=['Country'], \n",
    "                        value_vars=years_range, \n",
    "                        var_name='Year', \n",
    "                        value_name='Value')\n",
    "    \n",
    "    melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "    \n",
    "    fig = px.choropleth(melted_df, \n",
    "                        locations=\"Country\", \n",
    "                        locationmode='country names',  \n",
    "                        color=\"Value\", \n",
    "                        hover_name=\"Country\", \n",
    "                        animation_frame=\"Year\",  \n",
    "                        title=f\"Choropleth Map of Values Over Time ({file_name})\",\n",
    "                        color_continuous_scale=px.colors.sequential.Plasma)\n",
    "    \n",
    "    fig.update_coloraxes(cmin=melted_df['Value'].min(), \n",
    "                         cmax=melted_df['Value'].max(), \n",
    "                         colorbar_title=\"Value\")\n",
    "    \n",
    "    fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\", showland=True, landcolor=\"lightgray\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1200,  # Adjust width as needed\n",
    "        height=800,  # Adjust height as needed\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e68e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how value changes from year to year\n",
    "years_range = [str(year) for year in range(2012, 2023)]\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    for year in years_range:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "            \n",
    "    for i in range(1, len(years_range)):\n",
    "        current_year = years_range[i]\n",
    "        previous_year = years_range[i - 1]\n",
    "        percentage_change_column = f'% change {previous_year} to {current_year}'\n",
    "        \n",
    "        df.loc[:, percentage_change_column] = (\n",
    "            (df[current_year] - df[previous_year]) / df[previous_year]\n",
    "        ) * 100\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    print(f\"Head of the dataset '{file_name}':\")\n",
    "    display(df.head())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    #output_file_name = f\"updated_{file_name}\"\n",
    "    #df.to_csv(output_file_name, index=False)\n",
    "    #print(f\"Processed and saved: {output_file_name}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "949eadae-254c-4003-bc40-c69a90f0aefd",
   "metadata": {},
   "source": [
    "#at least one percentage change is greater than 100% based on 1980\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    years = [str(year) for year in range(2013, 2023)]\n",
    "    for year in years:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "    if '1980' in df.columns:\n",
    "        df['1980'] = pd.to_numeric(df['1980'], errors='coerce')\n",
    "\n",
    "    for year in years:\n",
    "        if '1980' in df.columns and year in df.columns:\n",
    "            change_col = f'% change of {year}'\n",
    "            df[change_col] = (df[year] / df['1980']) * 100\n",
    "            \n",
    "    change_columns = [col for col in df.columns if col.startswith('% change')]\n",
    "    df.replace([float('inf'), -float('inf')], np.nan, inplace=True)\n",
    "    df.dropna(subset=change_columns, inplace=True)\n",
    "    df = df[df[change_columns].gt(100).any(axis=1)]\n",
    "\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)\n",
    "\n",
    "melted_df = all_data.melt(id_vars=['Country'], \n",
    "                          value_vars=years, \n",
    "                          var_name='Year', \n",
    "                          value_name='Ratio')\n",
    "\n",
    "melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "\n",
    "fig = px.choropleth(melted_df, \n",
    "                    locations=\"Country\", \n",
    "                    locationmode='country names',  \n",
    "                    color=\"Ratio\", \n",
    "                    hover_name=\"Country\", \n",
    "                    animation_frame=\"Year\",  \n",
    "                    title=\"Choropleth Map of Emissions-to-GDP Ratios (2013-2022)\",\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "fig.update_coloraxes(cmin=melted_df['Ratio'].min(), \n",
    "                     cmax=melted_df['Ratio'].max(), \n",
    "                     colorbar_title=\"Emissions-to-GDP Ratio\")\n",
    "\n",
    "fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\", showland=True, landcolor=\"lightgray\")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,  \n",
    "    height=800, \n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff719274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GREATER THAN 100 ALL FILES (based on 1980)\n",
    "\n",
    "import numpy as np  \n",
    "\n",
    "years = [str(year) for year in range(2013, 2023)]\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    for year in years:\n",
    "        if year in filtered_df.columns:\n",
    "            filtered_df[year] = pd.to_numeric(filtered_df[year], errors='coerce')\n",
    "    if '1980' in filtered_df.columns:\n",
    "        filtered_df['1980'] = pd.to_numeric(filtered_df['1980'], errors='coerce')\n",
    "\n",
    "    for year in years:\n",
    "        if '1980' in filtered_df.columns and year in filtered_df.columns:\n",
    "            change_col = f'% change of {year}'\n",
    "            filtered_df.loc[:, change_col] = (filtered_df[year] / filtered_df['1980']) * 100\n",
    "\n",
    "    change_columns = [col for col in filtered_df.columns if col.startswith('% change')]\n",
    "\n",
    "    filtered_df.replace([float('inf'), -float('inf')], np.nan, inplace=True)  \n",
    "    filtered_df.dropna(subset=change_columns, inplace=True) \n",
    " \n",
    "    filtered_df = filtered_df[filtered_df[change_columns].gt(100).any(axis=1)]\n",
    "    \n",
    "    print(f\"Filtered rows with % change > 100 in the dataset '{file_name}':\")\n",
    "    display(filtered_df)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\") \n",
    "    \n",
    "    \n",
    "    #output_file_name = f\"updated_based_on_1980_{file_name}\"\n",
    "    #filtered_df.to_csv(output_file_name, index=False)\n",
    "    #print(f\"Processed and saved: {output_file_name}\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8d7b95e-5ee0-42b1-8e37-c9e34458258f",
   "metadata": {},
   "source": [
    "#increased by more than 100% relative to 1980 for at least one of the years => replicate \n",
    "\n",
    "years = [str(year) for year in range(2013, 2023)]\n",
    "\n",
    "# Assuming file_names is a list of CSV file paths\n",
    "for file_name in file_names:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    # Convert year columns and '1980' column to numeric\n",
    "    for year in years:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "    if '1980' in df.columns:\n",
    "        df['1980'] = pd.to_numeric(df['1980'], errors='coerce')\n",
    "\n",
    "    # Calculate % change relative to 1980\n",
    "    for year in years:\n",
    "        if '1980' in df.columns and year in df.columns:\n",
    "            change_col = f'% change of {year}'\n",
    "            df[change_col] = (df[year] / df['1980']) * 100\n",
    "\n",
    "    # Filter rows with % change > 100\n",
    "    change_columns = [col for col in df.columns if col.startswith('% change')]\n",
    "    df.replace([float('inf'), -float('inf')], np.nan, inplace=True)  \n",
    "    df.dropna(subset=change_columns, inplace=True)\n",
    "    filtered_df = df[df[change_columns].gt(100).any(axis=1)]\n",
    "\n",
    "    # Melt the DataFrame to long format for plotting\n",
    "    melted_df = filtered_df.melt(id_vars=['Country'], \n",
    "                                 value_vars=years, \n",
    "                                 var_name='Year', \n",
    "                                 value_name='Value')\n",
    "\n",
    "    # Extract year from 'Year' column\n",
    "    melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "\n",
    "    # Create the choropleth map\n",
    "    fig = px.choropleth(melted_df, \n",
    "                        locations=\"Country\", \n",
    "                        locationmode='country names',  \n",
    "                        color=\"Value\", \n",
    "                        hover_name=\"Country\", \n",
    "                        animation_frame=\"Year\",  \n",
    "                        title=f\"Choropleth Map of Values Over Time ({file_name})\",\n",
    "                        color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "    # Update color scale to fit the range of your data (optional)\n",
    "    fig.update_coloraxes(cmin=melted_df['Value'].min(), \n",
    "                         cmax=melted_df['Value'].max(), \n",
    "                         colorbar_title=\"Value\")\n",
    "\n",
    "    # Update map appearance\n",
    "    fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\", showland=True, landcolor=\"lightgray\")\n",
    "\n",
    "    # Increase the size of the map\n",
    "    fig.update_layout(\n",
    "        width=1200,  # Adjust width as needed\n",
    "        height=800,  # Adjust height as needed\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a23e041-7456-4eae-9ffd-265b6cbeee7f",
   "metadata": {},
   "source": [
    "#DATASET FOR YEAR TO YEAR CHANGE \n",
    "\n",
    "emission_types = ['        CO2 emissions (MMtonnes CO2)',\n",
    "    '            Coal and coke (MMtonnes CO2)',\n",
    "    '            Consumed natural gas (MMtonnes CO2)',\n",
    "    '            Petroleum and other liquids (MMtonnes CO2)'\n",
    "]\n",
    "\n",
    "\n",
    "selected_emissions_df = df[df['Type of Emission'].isin(emission_types)].copy()\n",
    "\n",
    "years_range = [str(year) for year in range(2012, 2023)]\n",
    "for year in years_range:\n",
    "    if year in selected_emissions_df.columns:\n",
    "        selected_emissions_df[year] = pd.to_numeric(selected_emissions_df[year], errors='coerce')\n",
    "\n",
    "for i in range(1, len(years_range)):\n",
    "    current_year = years_range[i]\n",
    "    previous_year = years_range[i - 1]\n",
    "    percentage_change_column = f'% change {previous_year} to {current_year}'\n",
    "    \n",
    "    selected_emissions_df.loc[:, percentage_change_column] = (\n",
    "        (selected_emissions_df[current_year] - selected_emissions_df[previous_year]) / selected_emissions_df[previous_year]\n",
    "    ) * 100\n",
    "\n",
    "# selected_emissions_df.to_csv('updated_emissions_data.csv', index=False)\n",
    "\n",
    "selected_emissions_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "982901d4-f456-48d8-b8e3-66d52d8e4f43",
   "metadata": {},
   "source": [
    "#ONLY INCREASING VALUES FOR YEAR TO YEAR CHANGE (only for emissions)\n",
    "\n",
    "change_columns1 = [col for col in selected_emissions_df.columns if col.startswith('% change')]\n",
    "\n",
    "positive_rows1 = selected_emissions_df[change_columns1].apply(lambda x: (x > 0).all(), axis=1)\n",
    "\n",
    "result1 = selected_emissions_df[positive_rows1]\n",
    "result1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e293762-3b55-4c9e-a954-bce479866686",
   "metadata": {},
   "source": [
    "#DATASET FOR YEAR TO YEAR CHANGE BASED ON 1980 (only for emissions)\n",
    "\n",
    "filtered_df = df[df['Type of Emission'].isin(emission_types)].copy() \n",
    "\n",
    "years = [str(year) for year in range(2013, 2023)] \n",
    "for year in years:\n",
    "    filtered_df[year] = pd.to_numeric(filtered_df[year], errors='coerce')\n",
    "filtered_df['1980'] = pd.to_numeric(filtered_df['1980'], \n",
    "                                                           errors='coerce')\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    change_col = f'% change of {year}'\n",
    "    \n",
    "    filtered_df.loc[:, change_col] = (filtered_df[year] / filtered_df['1980']) * 100\n",
    "\n",
    "#filtered_df.to_csv('updated_data.csv', index=False)\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbceee0f-1623-4532-aa08-fd44fdd81143",
   "metadata": {},
   "source": [
    "#INCREASE FOR STOCK YEAR (only for emissions)\n",
    "\n",
    "change_columns = [col for col in filtered_df.columns if col.startswith('% change of ')]\n",
    "\n",
    "filtered_rows = filtered_df[change_columns].apply(lambda x: x > 100, axis=1)\n",
    "\n",
    "result = filtered_df.loc[filtered_rows.any(axis=1)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282690b-c164-47b1-b2cb-664c5628d5ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rows where at least one percentage change value exceeds 100% based on 1980\n",
    "\n",
    "years = [str(year) for year in range(2013, 2023)]\n",
    "\n",
    "# Define file names\n",
    "file_names = [\n",
    "    \"merged_processed_Coal and coke.csv\",\n",
    "    \"merged_processed_Natural gas.csv\",\n",
    "    \"merged_processed_Petroleum and other liquids.csv\",\n",
    "    \"merged_processed_Biofuels.csv\",\n",
    "    \"merged_processed_Electricity.csv\",\n",
    "    \"merged_modified2_primary_energy.csv\",\n",
    "    \"merged_processed_emissions_modified.csv\"\n",
    "]\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(file_name)\n",
    "    \n",
    "    for year in years:\n",
    "        if year in df.columns:\n",
    "            df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "    \n",
    "    if '1980' in df.columns:\n",
    "        df['1980'] = pd.to_numeric(df['1980'], errors='coerce')\n",
    "    \n",
    "    #percentage change from 1980\n",
    "    for year in years:\n",
    "        if '1980' in df.columns and year in df.columns:\n",
    "            change_col = f'% change of {year}'\n",
    "            df[change_col] = (df[year] / df['1980']) * 100\n",
    "    \n",
    "    #  % change > 100\n",
    "    change_columns = [col for col in df.columns if col.startswith('% change of ')]\n",
    "    df.replace([float('inf'), -float('inf')], np.nan, inplace=True)\n",
    "    df.dropna(subset=change_columns, inplace=True)\n",
    "    \n",
    "    # percentage change is > 100\n",
    "    filtered_rows = df[change_columns].apply(lambda x: x > 100, axis=1)\n",
    "    filtered_df = df.loc[filtered_rows.any(axis=1)]\n",
    "    \n",
    "    melted_df = filtered_df.melt(id_vars=['Country'], \n",
    "                                 value_vars=years, \n",
    "                                 var_name='Year', \n",
    "                                 value_name='Value')\n",
    "\n",
    "    melted_df['Year'] = melted_df['Year'].astype(int)\n",
    "\n",
    "    fig = px.choropleth(melted_df, \n",
    "                        locations=\"Country\", \n",
    "                        locationmode='country names',  \n",
    "                        color=\"Value\", \n",
    "                        hover_name=\"Country\", \n",
    "                        animation_frame=\"Year\",  \n",
    "                        title=f\"Choropleth Map of Values Over Time ({file_name})\",\n",
    "                        color_continuous_scale=px.colors.sequential.Plasma)\n",
    "\n",
    "    fig.update_coloraxes(cmin=melted_df['Value'].min(), \n",
    "                         cmax=melted_df['Value'].max(), \n",
    "                         colorbar_title=\"Value\")\n",
    "\n",
    "    fig.update_geos(showcoastlines=True, coastlinecolor=\"Black\", showland=True, landcolor=\"lightgray\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1200, \n",
    "        height=800,  \n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8053dd9d-1259-4e04-a650-d5cff0df9148",
   "metadata": {},
   "source": [
    "df_coal = pd.read_csv('processed_Coal and coke.csv')\n",
    "df_coal['Country'] = df_coal['Country'].str.replace(' ', '')\n",
    "\n",
    "df_merged = pd.merge(df_coal, dfA, on='Country', how='left', suffixes=('', '_dfA'))\n",
    "\n",
    "df_merged = df_merged.loc[:, ~df_merged.columns.str.contains('_dfA')] \n",
    "\n",
    "df_merged.to_csv('processed_Coal and coke.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120beaa",
   "metadata": {},
   "source": [
    "# FAILURES SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coal = pd.read_csv('merged_processed_Coal and coke.csv')\n",
    "latitude_col = 'Latitude_x'  \n",
    "quantity_col = '2022'     \n",
    "\n",
    "coal[quantity_col] = pd.to_numeric(coal[quantity_col], errors='coerce')\n",
    "df_filtered = coal[(coal[quantity_col].notna()) & (coal[quantity_col] > 0)]\n",
    "\n",
    "df_filtered = df_filtered.sort_values(by=quantity_col)\n",
    "\n",
    "fig = px.scatter(df_filtered, x=latitude_col, y=quantity_col,\n",
    "                 title='Coal and Coke Quantity vs. Latitude in 2022',\n",
    "                 labels={latitude_col: 'Latitude', quantity_col: 'Quantity (2022)'})\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ecf7f7-97e7-48e7-8b00-7d22f610c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9fb3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_coal2 = pd.read_csv('merged_processed_Coal and coke.csv')\n",
    "df_natural_gas = pd.read_csv('merged_processed_Natural gas.csv')\n",
    "df_petroleum = pd.read_csv('merged_processed_Petroleum and other liquids.csv')\n",
    "\n",
    "latitude_col = 'Latitude' \n",
    "quantity_col = '2022'      \n",
    "\n",
    "\n",
    "def preprocess_data(df, source_name):\n",
    "\n",
    "    df[quantity_col] = pd.to_numeric(df[quantity_col], errors='coerce')\n",
    "    \n",
    "    df_filtered = df[(df[quantity_col].notna()) & (df[quantity_col] > 0)].copy()\n",
    "    \n",
    "    df_filtered['Source'] = source_name\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "df_coal_filtered = preprocess_data(df_coal2, 'Coal and Coke')\n",
    "df_natural_gas_filtered = preprocess_data(df_natural_gas, 'Natural Gas')\n",
    "df_petroleum_filtered = preprocess_data(df_petroleum, 'Petroleum and Other Liquids')\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df_coal_filtered, df_natural_gas_filtered, df_petroleum_filtered])\n",
    "\n",
    "df_combined = df_combined.sort_values(by=quantity_col)\n",
    "\n",
    "fig = px.scatter(df_combined, x=latitude_col, y=quantity_col, color='Source',\n",
    "                 title='Natural Resource Quantity vs. Latitude in 2022',\n",
    "                 labels={latitude_col: 'Latitude', quantity_col: 'Quantity (2022)', 'Source': 'Resource Type'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47838e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latitude_col = 'Latitude' \n",
    "quantity_col = '2022'  \n",
    "\n",
    "def preprocess_data(df, source_name):\n",
    "    df[quantity_col] = pd.to_numeric(df[quantity_col], errors='coerce')\n",
    "    \n",
    "    df_filtered = df[(df[quantity_col].notna()) & (df[quantity_col] > 0)].copy()\n",
    "    \n",
    "    df_filtered.loc[:, 'Source'] = source_name\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "df_coal_filtered = preprocess_data(df_coal2, 'Coal and Coke')\n",
    "df_natural_gas_filtered = preprocess_data(df_natural_gas, 'Natural Gas')\n",
    "df_petroleum_filtered = preprocess_data(df_petroleum, 'Petroleum and Other Liquids')\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df_coal_filtered, df_natural_gas_filtered, df_petroleum_filtered])\n",
    "\n",
    "def calculate_percentile_range(df, col, lower_percentile=5, upper_percentile=95):\n",
    "    lower_bound = df[col].quantile(lower_percentile / 100)\n",
    "    upper_bound = df[col].quantile(upper_percentile / 100)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "\n",
    "x_min, x_max = calculate_percentile_range(df_combined, latitude_col)\n",
    "y_min, y_max = calculate_percentile_range(df_combined, quantity_col)\n",
    "\n",
    "\n",
    "fig = px.scatter(df_combined, x=latitude_col, y=quantity_col, color='Source',\n",
    "                 title='Natural Resource Quantity vs. Latitude in 2022',\n",
    "                 labels={latitude_col: 'Latitude', quantity_col: 'Quantity (2022)', 'Source': 'Resource Type'})\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(range=[x_min, x_max]),\n",
    "    yaxis=dict(range=[y_min, y_max])\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205aca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_col = 'Latitude'  \n",
    "longitude_col = 'Longitude' \n",
    "quantity_col = '2022'       \n",
    "\n",
    "def preprocess_data(df, source_name):\n",
    "    df[quantity_col] = pd.to_numeric(df[quantity_col], errors='coerce')\n",
    "    \n",
    "    df_filtered = df[(df[quantity_col].notna()) & (df[quantity_col] > 0)].copy()\n",
    "    \n",
    "    df_filtered.loc[:, 'Source'] = source_name\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "df_coal_filtered = preprocess_data(df_coal2, 'Coal and Coke')\n",
    "df_natural_gas_filtered = preprocess_data(df_natural_gas, 'Natural Gas')\n",
    "df_petroleum_filtered = preprocess_data(df_petroleum, 'Petroleum and Other Liquids')\n",
    "\n",
    "\n",
    "df_combined = pd.concat([df_coal_filtered, df_natural_gas_filtered, df_petroleum_filtered])\n",
    "\n",
    "\n",
    "def calculate_percentile_range(df, col, lower_percentile=5, upper_percentile=95):\n",
    "    lower_bound = df[col].quantile(lower_percentile / 100)\n",
    "    upper_bound = df[col].quantile(upper_percentile / 100)\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "x_min_lat, x_max_lat = calculate_percentile_range(df_combined, latitude_col)\n",
    "x_min_lon, x_max_lon = calculate_percentile_range(df_combined, longitude_col)\n",
    "y_min, y_max = calculate_percentile_range(df_combined, quantity_col)\n",
    "\n",
    "\n",
    "fig = px.scatter(df_combined, x=longitude_col, y=quantity_col, color='Source',\n",
    "                 title='Natural Resource Quantity vs. Longitude in 2022',\n",
    "                 labels={longitude_col: 'Longitude', quantity_col: 'Quantity (2022)', 'Source': 'Resource Type'})\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(range=[x_min_lon, x_max_lon]),\n",
    "    yaxis=dict(range=[y_min, y_max])\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c37529",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'merged_processed_Coal and coke.csv',\n",
    "    'merged_processed_Natural gas.csv',\n",
    "    'merged_processed_Petroleum and other liquids.csv',\n",
    "    'merged_processed_Biofuels.csv',\n",
    "    'merged_processed_Electricity.csv',\n",
    "    'merged_modified2_primary_energy.csv',\"merged_processed_emissions_modified.csv\"\n",
    "]\n",
    "\n",
    "latitude_col = 'Latitude' \n",
    "quantity_col = '2022'      \n",
    "\n",
    "def preprocess_data(df, source_name):\n",
    "    if quantity_col not in df.columns:\n",
    "        print(f\"Warning: '{quantity_col}' column not found in dataset '{source_name}'\")\n",
    "        return pd.DataFrame()  \n",
    "    \n",
    "    df[quantity_col] = pd.to_numeric(df[quantity_col], errors='coerce')\n",
    "    \n",
    "\n",
    "    df_filtered = df[(df[quantity_col].notna()) & (df[quantity_col] > 0)].copy()\n",
    "    \n",
    "    df_filtered.loc[:, 'Source'] = source_name\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "dfs_filtered = []\n",
    "for file in files:\n",
    "    source_name = file.split('.')[0] \n",
    "    df = pd.read_csv(file)\n",
    "    df_filtered = preprocess_data(df, source_name)\n",
    "    if not df_filtered.empty:\n",
    "        dfs_filtered.append(df_filtered)\n",
    "\n",
    "if dfs_filtered:\n",
    "    df_combined = pd.concat(dfs_filtered)\n",
    "    \n",
    "    def calculate_percentile_range(df, col, lower_percentile=5, upper_percentile=95):\n",
    "        lower_bound = df[col].quantile(lower_percentile / 100)\n",
    "        upper_bound = df[col].quantile(upper_percentile / 100)\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    x_min, x_max = calculate_percentile_range(df_combined, latitude_col)\n",
    "    y_min, y_max = calculate_percentile_range(df_combined, quantity_col)\n",
    "\n",
    "    fig = px.scatter(df_combined, x=latitude_col, y=quantity_col, color='Source',\n",
    "                     title='Natural Resource Quantity vs. Latitude in 2022',\n",
    "                     labels={latitude_col: 'Latitude', quantity_col: 'Quantity (2022)', 'Source': 'Resource Type'})\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(range=[x_min, x_max]),\n",
    "        yaxis=dict(range=[y_min, y_max])\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data available for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_col = 'Longitude'  \n",
    "quantity_col = '2022'        \n",
    "\n",
    "def preprocess_data(df, source_name):\n",
    "    if quantity_col not in df.columns:\n",
    "        print(f\"Warning: '{quantity_col}' column not found in dataset '{source_name}'\")\n",
    "        return pd.DataFrame()  \n",
    "    \n",
    "    df[quantity_col] = pd.to_numeric(df[quantity_col], errors='coerce')\n",
    "    \n",
    "    df_filtered = df[(df[quantity_col].notna()) & (df[quantity_col] > 0)].copy()\n",
    "    \n",
    "    df_filtered.loc[:, 'Source'] = source_name\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "dfs_filtered = []\n",
    "for file in files:\n",
    "    source_name = file.split('.')[0] \n",
    "    df = pd.read_csv(file)\n",
    "    df_filtered = preprocess_data(df, source_name)\n",
    "    if not df_filtered.empty:\n",
    "        dfs_filtered.append(df_filtered)\n",
    "\n",
    "if dfs_filtered:\n",
    "    df_combined = pd.concat(dfs_filtered)\n",
    "    \n",
    "    def calculate_percentile_range(df, col, lower_percentile=5, upper_percentile=95):\n",
    "        lower_bound = df[col].quantile(lower_percentile / 100)\n",
    "        upper_bound = df[col].quantile(upper_percentile / 100)\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    x_min, x_max = calculate_percentile_range(df_combined, longitude_col)\n",
    "    y_min, y_max = calculate_percentile_range(df_combined, quantity_col)\n",
    "\n",
    "    fig = px.scatter(df_combined, x=longitude_col, y=quantity_col, color='Source',\n",
    "                     title='Natural Resource Quantity vs. Longitude in 2022',\n",
    "                     labels={longitude_col: 'Longitude', quantity_col: 'Quantity (2022)', 'Source': 'Resource Type'})\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(range=[x_min, x_max]),\n",
    "        yaxis=dict(range=[y_min, y_max])\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No data available for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT= pd.read_csv(\"merged_processed_emissions_modified.csv\")\n",
    "dfT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a9d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b283af-6c47-4793-830d-72fb7e84c0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e903f-7c5e-407b-9d6c-431aa5a1de11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98264f4d-bf63-42ff-b700-834b0d0c48f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
